{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 1: Customer Complaints Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1588650093575,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "S-g6Yo6lCham",
    "outputId": "ad799dcf-9f95-43c2-a597-9e2fdbb7c64d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import nltk\n",
    "nltk.download(\"popular\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHWI7yyUDN6q"
   },
   "outputs": [],
   "source": [
    "complaints = pd.read_csv(\"https://raw.githubusercontent.com/wsko/Text_Analytics_Case_Studies/master/complaints01.csv\")\n",
    "complaintsRaw = complaints.Consumer_complaint.values[:5000]\n",
    "complaintsRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Standardize / clean-up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2497,
     "status": "ok",
     "timestamp": 1588650094946,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "913oFHebQGd0",
    "outputId": "41109050-c068-4240-e318-fba4ff5d0da8"
   },
   "outputs": [],
   "source": [
    "s = complaintsRaw[9]##sample text\n",
    "z = word_tokenize(s)\n",
    "print(s)\n",
    "print(\" \")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Remove stopwords and convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [word for word in z if word.lower() not in stopwords.words('english')]##remove stopwords\n",
    "z = [word.lower() for word in z]##convert everything to lower case\n",
    "print(s)\n",
    "print(\" \")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [stemmer.stem(word) for word in z]##stem similar words)\n",
    "z = ' '.join(z)\n",
    "print(s)\n",
    "print(\" \")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Create a text clean-up function and apply it to the raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oIaOl08I0Gg"
   },
   "outputs": [],
   "source": [
    "def cleantext(s):\n",
    "  z = word_tokenize(s)\n",
    "  z = [word.lower() for word in z]##convert everything to lower case\n",
    "  z = [word for word in z if word.lower() not in stopwords.words('english')]##remove stopwords\n",
    "  z = [stemmer.stem(word) for word in z]##stem similar words)\n",
    "  z = [word for word in z if word not in [\".\", \",\", \" \", \"xx\",\"xxx\", \"xxxx\", \"xxxxxxxx\", \"xx/xx/xxxx\", \"xx/xx/2019\", \"xx/xx/2018\", \"xx/xx/2017\", \"00\", \"0.00\", \"000\"]]##remove custom tokens\n",
    "  return(' '.join(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2472,
     "status": "ok",
     "timestamp": 1588650094946,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "x67RW12RR6Ai",
    "outputId": "0d495e4c-c011-49c4-8ff9-6dc7d895b743"
   },
   "outputs": [],
   "source": [
    "cleantext(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKlz6_7kJTfR"
   },
   "outputs": [],
   "source": [
    "#complaintsClean = complaintsRaw.copy()\n",
    "#for i in range(len(complaintsRaw)):\n",
    "#  complaintsClean[i] = cleantext(complaintsRaw[i])\n",
    "complaintsClean = pd.read_csv(\"https://raw.githubusercontent.com/wsko/Text_Analytics_Case_Studies/master/complaintsClean.csv\")['complaintsClean'].values\n",
    "complaintsClean[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a document-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X49ZWPGoJ0Wr"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(complaintsClean)\n",
    "dtm = vec.transform(complaintsClean)##docuent-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127243,
     "status": "ok",
     "timestamp": 1588650219782,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "YfTQyudavd2U",
    "outputId": "2925765c-20e2-4742-da34-0d28ee42aa03"
   },
   "outputs": [],
   "source": [
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127633,
     "status": "ok",
     "timestamp": 1588650220211,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "zW7OVt3A2mTB",
    "outputId": "6a6e0b79-eca5-484f-aaac-dd6c71067099"
   },
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame({'Number' : list(vec.vocabulary_.values()), 'Key' : list(vec.vocabulary_.keys())})\n",
    "vocab.sort_values(by = 'Number', inplace = True)\n",
    "topWords = pd.DataFrame({\"Keys\" : vocab.Key, 'Freq': dtm.toarray().sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)\n",
    "topWords.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127548,
     "status": "ok",
     "timestamp": 1588650220212,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "ZddbCmB5an1X",
    "outputId": "fea5d35b-85ae-4d2a-cc9b-1bd47a02e289"
   },
   "outputs": [],
   "source": [
    "DTM = pd.DataFrame(dtm.toarray())\n",
    "DTM.columns = vocab.Key.values\n",
    "DTM[topWords.Keys.values[:20]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127538,
     "status": "ok",
     "timestamp": 1588650220213,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "HzjAd0AobE6s",
    "outputId": "be06f067-2f8f-4f52-ba00-b50436a8f7ae"
   },
   "outputs": [],
   "source": [
    "##Text representation as a bag of words\n",
    "print(\"Clean Text:\")\n",
    "print(complaintsClean[0])\n",
    "print(\"  \")\n",
    "DTM[complaintsClean[0].split()].iloc[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Perform TF-IDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjgBnlgnKBk3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer().fit(dtm)\n",
    "X = tfidf.transform(dtm)\n",
    "X = X.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127715,
     "status": "ok",
     "timestamp": 1588650220450,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "jzzf71ZgKHNj",
    "outputId": "e3082234-1e85-4f7d-c440-eaacae41160a"
   },
   "source": [
    "#### Reduce number of columns based on total variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127975,
     "status": "ok",
     "timestamp": 1588650220742,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "IgI9kddi26su",
    "outputId": "3681dc49-4f1b-47ca-ea3a-9dd175df6269"
   },
   "outputs": [],
   "source": [
    "sum(X.var(axis = 0) > 0.02*X.var(axis = 0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9L8oqu13huU"
   },
   "outputs": [],
   "source": [
    "X1 = X[:, X.var(axis = 0) > 0.02*X.var(axis = 0).max()]\n",
    "vocab1 = vocab[X.var(axis = 0) > 0.02*X.var(axis = 0).max()]\n",
    "topWords1 = pd.DataFrame({\"Keys\" : vocab1.Key, 'Freq': X1.sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)\n",
    "TFIDF = pd.DataFrame(X1)\n",
    "TFIDF.columns = vocab1.Key.values\n",
    "TFIDF[topWords1.Keys.values[:10]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 129215,
     "status": "ok",
     "timestamp": 1588650222017,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "eUl20sWBc23G",
    "outputId": "74bc50ff-354d-4c8d-d56a-5acbfa55ce06"
   },
   "source": [
    "### 4. Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDPjNvUiKpLi"
   },
   "outputs": [],
   "source": [
    "### create a column \"complaintType\"\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=12).fit(X1)\n",
    "complaintType = KMeans(n_clusters=4, random_state=None).fit_predict(X1) + 1\n",
    "pd.DataFrame({\"TYPE\":pd.Series(complaintType).value_counts().index, \"Counts\":pd.Series(complaintType).value_counts().values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 144483,
     "status": "ok",
     "timestamp": 1588650237327,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "7ZKaGadlKzRS",
    "outputId": "cce6ff17-a865-4dd1-eacb-1b5d3268437c"
   },
   "source": [
    "#### Most frequent words in each complaint cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 144464,
     "status": "ok",
     "timestamp": 1588650237329,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "C6fPVuZ8K2PY",
    "outputId": "612baa24-1603-4c39-8828-e4eff0dddac4"
   },
   "outputs": [],
   "source": [
    "for i in range(1,5):\n",
    "  print(\"complaint type\", i, \":\", \"\\n\", pd.DataFrame({\"Keys\" : vocab1.Key, 'Freq': X1[complaintType == i].sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)['Keys'].values[:10])\n",
    "  print(\"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Categorize customer complaints; save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## List categories based on the most frequent words\n",
    "Categories = []\n",
    "Categorized = pd.DataFrame({'Complaint_Type':\"\", \"Complaint\":complaintsRaw})\n",
    "for i in range(len(complaintsRaw)):\n",
    "    Categorized[\"Complaint_Type\"][i] = Categories[complaintType[i]-1]\n",
    "Categorized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "Categorized.to_csv('Complaints_Categorized.csv')\n",
    "files.download('Complaints_Categorized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study 2: Competitive Intelligence\n",
    "## What has Tech Company X been up to?\n",
    "### (Patent Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patent document - example\n",
    "http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=8&f=G&l=50&co1=AND&d=PTXT&s1=skorokhod.INNM.&s2=xerox.ASNM.&OS=IN/skorokhod+AND+AN/xerox&RS=IN/skorokhod+AND+AN/xerox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have about 400 abstracts from patents filed by \"Tech Company X\" over the past couple of years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1588559320267,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "aWzrjqllkmWz",
    "outputId": "4b6dc5e3-36a5-4ba9-e33c-da07ae9bf46b"
   },
   "outputs": [],
   "source": [
    "abstractRaw = pd.read_csv('https://raw.githubusercontent.com/wsko/Text_Analytics_Case_Studies/master/abstract.csv').abstract.values\n",
    "abstractRaw[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's vectorize the abstracts using the process similar to what we did in the previous case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5FjrFDHenG2f"
   },
   "outputs": [],
   "source": [
    "def cleantext(s):\n",
    "  z = word_tokenize(s)\n",
    "  z = [word for word in z if word.lower() not in stopwords.words('english')]##remove stopwords\n",
    "  z = [word.lower() for word in z]##convert everything to lower case\n",
    "  #z = [stemmer.stem(word) for word in z]##stemming\n",
    "  z = [word for word in z if word not in [\".\", \",\", \" \", \"first\", \"second\", \"may\", \"provid\", \"may\", \"least\"]]##remove custom tokens\n",
    "  return(' '.join(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1588559082616,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "O0Ifq2W3zwuM",
    "outputId": "5264d07f-fc3a-4f49-f0f2-2acd66b18ae8"
   },
   "outputs": [],
   "source": [
    "print(abstractRaw[0])\n",
    "print(\"  \")\n",
    "print(cleantext(abstractRaw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foZ2s74GzyN5"
   },
   "outputs": [],
   "source": [
    "abstract = abstractRaw.copy()\n",
    "for i in range(len(abstractRaw)):\n",
    "    abstract[i] = cleantext(abstract[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1588559354331,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "lmVDsOXF1RIY",
    "outputId": "5481f7de-67f2-49be-8578-f335790448ad"
   },
   "outputs": [],
   "source": [
    "abstract[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X49ZWPGoJ0Wr"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer()\n",
    "vec.fit(abstract)\n",
    "dtm = vec.transform(abstract)##docuent-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501,
     "status": "ok",
     "timestamp": 1588559926266,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "zW7OVt3A2mTB",
    "outputId": "98b3f0a8-53e1-4553-8b7c-a20bf16d5ce3"
   },
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame({'Number' : list(vec.vocabulary_.values()), 'Key' : list(vec.vocabulary_.keys())})\n",
    "vocab.sort_values(by = 'Number', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zjgBnlgnKBk3"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer().fit(dtm)\n",
    "TFIDF = tfidf.transform(dtm)\n",
    "X = TFIDF.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1588559941254,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "jzzf71ZgKHNj",
    "outputId": "c7a1140e-7ab4-4ce0-c195-986766c8e5f1"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1588559944675,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "O3qy7yr7_z9g",
    "outputId": "3c254429-baab-4064-8589-45b69573203d"
   },
   "outputs": [],
   "source": [
    "topWords = pd.DataFrame({\"Keys\" : vocab.Key, 'Freq': X.sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)\n",
    "DTM = pd.DataFrame(X)\n",
    "DTM.columns = vocab.Key.values\n",
    "DTM[topWords.Keys.values[:20]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUl20sWBc23G"
   },
   "source": [
    "#### Next, find document clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDPjNvUiKpLi"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5).fit(X)\n",
    "ClusterID = KMeans(n_clusters=5, random_state=None).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1588559958544,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "7ZKaGadlKzRS",
    "outputId": "815c5ce0-6ca2-4711-fba6-5bc9f490fa4e"
   },
   "outputs": [],
   "source": [
    "pd.Series(ClusterID).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 743,
     "status": "ok",
     "timestamp": 1588559960466,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "C6fPVuZ8K2PY",
    "outputId": "78a11537-856f-4df9-aab9-82552229d5de"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  print(\"ClusterID\", i, pd.DataFrame({\"Keys\" : vocab.Key, 'Freq': X[ClusterID == i].sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)['Keys'].values[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, visualize each patent cluster as a word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txCGR3hp9TNt"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2468,
     "status": "ok",
     "timestamp": 1588562837473,
     "user": {
      "displayName": "Vlad Skorokhod",
      "photoUrl": "",
      "userId": "12641846192617263153"
     },
     "user_tz": 240
    },
    "id": "uqjVAL3O_F7W",
    "outputId": "aa05ac41-dfd9-4b2c-cf20-54ace1eda4f5"
   },
   "outputs": [],
   "source": [
    "N = 1\n",
    "weights = pd.DataFrame({\"Keys\" : vocab.Key, 'Freq': X[ClusterID == N, :].sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)[:100]\n",
    "weights = dict([tuple(x) for x in weights.to_numpy()])\n",
    "print(\"ClusterID\", N, pd.DataFrame({\"Keys\" : vocab.Key, 'Freq': X[ClusterID == N].sum(axis = 0)}).sort_values(by = 'Freq', ascending = False)['Keys'].values[:8])\n",
    "wordcloud = WordCloud(width = 400, height = 400, background_color ='white', min_font_size = 10).generate_from_frequencies(weights)\n",
    "plt.figure(figsize = (6, 6), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "#plt.tight_layout(pad = 0)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCnTwL4VfZJz"
   },
   "source": [
    "#### Bonus: how to web scrape patent abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLJuH_7KfZs5"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "pnum = \"10645525\"\n",
    "url_1 = 'http://patft1.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&d=PALL&p=1&u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&r=1&f=G&l=50&s1='\n",
    "url_2 = '.PN.&OS=PN/'\n",
    "url_3 = '&RS=PN/'\n",
    "url = url_1+pnum+url_2+pnum+url_3+pnum\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "page.close()\n",
    "list(list(soup.children)[14].stripped_strings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text_Analytics_Case_Study_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
